# Installation

MCMSEM uses [torch for R](https://torch.mlverse.org/), which allows for computation on either CPU or GPU.
We recommend starting out with the default CPU installation, if you want to run MCMSEM on GPU instead, skip the CPU installation steps and go straight to GPU.
Note the GPU installation still allows for CPU computation, so you will never need both.

## Installing MCMSEM (for CPU)

Currently this packge is not listed on CRAN and should therefore be installed from GitHub directly.

First, load the `devtools` package, then use `install_github` to install the package directly from GitHub.
```
library(devtools)
install_github("https://github.com/zenabtamimy/MCMSEM")
```

Note that the first time you load MCMSEM (or torch seperately) may take a few minutes as torch has to download additional files.

### CPU threading

As MCMSEM uses `torch` as a backend it will automatically use all available cores on your machine. You can use `torch_set_num_threads()` or `torch_set_num_interop_threads()` do decrease this number. See [torch documentation](https://pytorch.org/docs/stable/notes/cpu_threading_torchscript_inference.html?highlight=set_num_threads).

## Installing MCMSEM for GPU

> A CUDA-enabled installation of torch still allows for CPU computation, if you wish to use a CPU instead and have a CUDA-enabled torch installation, simply setup a CPU device.

**Preface**: Using a GPU is only advantageous under certain circumstances. 
Generally, if your intended model contains 5 or fewer input variables, or if you intend to run a model without kurtosis it will likely not be worth it, though this will all depend on your model, data, CPU, GPU etc.
When used in the right circumstances, generally very large models with more then 15 variables, running `MCMfit` on a GPU can result in **very** significant (>100x) runtime improvements.  
This, however, is contingent upon enough available VRAM. More on `CUDA out of memory` errors below.

### Requirements
1. An NVIDIA CUDA-enabled GPU, see [NVIDIA's website](https://developer.nvidia.com/cuda-gpus).
   - On top of this you will need a GPU with enough VRAM capacity. At least 4GB is recommended, but ideally it should be more.
2. Installed NVIDIA CUDA toolkit version 11.3 (note it has to be **exactly** version 11.3), see [NVIDIA's website](https://developer.nvidia.com/cuda-toolkit)
    - Make sure that environmental variables CUDA_HOME and CUDA_PATH are set properly
3. Installed cuDNN 8.4 for CUDA toolkit 11.3 see [NVIDIA's website](https://developer.nvidia.com/cudnn) (again, it has to be **exactly** version 8.4).

### Installing torch
Once all requirements have been met, install torch from scratch. If you already have torch for R installed (or have already installed a package that requires it such as MCMSEM), remove it: `remove.packages("torch")`, restart R, and install it again.  
In some cases environment variables may not be properly set after installation of CUDA toolkit, if this happens, and your torch installation does not find an available CUDA device, remove torch again, restart R, then run `Sys.setenv()` to set the variables `CUDA_HOME` and `CUDA_PATH` to the install directory of CUDA toolkit prior to re-installing torch.

Note that the first time you load MCMSEM (or torch seperately) may take a few minutes as torch has to download additional files, and the GPU version takes noticeably longer.

### Usage
Before running MCMSEM, verify that CUDA is available to your torch installation. Note that the first time you run `library(torch)` might take a few minutes as torch will then download and install required gpu-torch libraries.
``` 
library(torch)
cuda_is_available()  # Should return TRUE
```

If CUDA is available, setup a CUDA device and pass this to MCMfit.
``` 
cuda_device <- torch_device("cuda")
res <- MCMfit(my_model, data, device=cuda_device)
```

### CUDA out of memory
If you get a `CUDA out of memory` error your VRAM is insufficient given your model.
First, try using `MCMfit(..., low_memory=TRUE)`, this will run a more memory-friendly version of the optimization at the cost of runtime (note this cost gets VERY significant with large (>30 variables) models).  
If you still run into CUDA out of memory errors after setting `low_memory` to TRUE your current model cannot be optimized on your GPU, your options are:
 - Drop all covariances from the `S` matrix
>*If S is a diagnoal matrix MCMSEM will run more memory-efficient types of matrix multiplications.*
 - Decrease the size of your model by dropping input variables, removing latent variables, or not modeling kurtosis (set use_kurtosis = FALSE`).
>*Especially not considering kurtosis will save a significant ammount of VRAM, however decreasing the size of your model may not fit your purpose, and disabling kurtosis may lead to worse estiamtion of parameters.* 
 - Run your model on CPU instead by removing the `device` argument from `MCMfit()`
>*It is highly recommended to also disable kurtosis when running your model on CPU, especially if the model is large. Models with >25 variables that model the kurtosis may well take days to optimize on CPU only.* 
 - Get access to a GPU with more VRAM
>*In all cases the best option, albeit the most expensive one, consider a cloud GPU, see the wiki `MCSEM on the cloud`.*

Note that removing objects from your R environment, or closing other running applications will only save RAM, not VRAM (unless you are gaming while a model runs in the background, in which case try closing that first), so this is very unlikely to help.

